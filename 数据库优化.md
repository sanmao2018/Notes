## 数据库优化

### 利用mysql limit分页优化全表查询

Mysql的分页查询语句的性能分析

MySql分页sql语句，如果和MSSQL的TOP语法相比，那么MySQL的LIMIT语法要显得优雅了许多。使用它来分页是再自然不过的事情了。

最基本的分页方式：
SELECT ... FROM ... WHERE ... ORDER BY ... LIMIT ...

在中小数据量的情况下，这样的SQL足够用了，唯一需要注意的问题就是确保使用了索引： 
举例来说，如果实际SQL类似下面语句，那么在category_id, id两列上建立复合索引比较好：
SELECT * FROM articles WHERE category_id = 123 ORDER BY id LIMIT 50, 10

子查询的分页方式：
随着数据量的增加，页数会越来越多，查看后几页的SQL就可能类似：
SELECT * FROM articles WHERE category_id = 123 ORDER BY id LIMIT 10000, 10

总的来说，就是越往后分页，LIMIT语句的偏移量就会越大，速度也会明显变慢。 
此时，我们可以通过子查询的方式来提高分页效率，大致如下：

SELECT * FROM articles WHERE id >= 
(SELECT id FROM articles WHERE category_id = 123 ORDER BY id LIMIT 10000, 1) LIMIT 10


JOIN分页方式
SELECT * FROM `content` AS t1 
JOIN (SELECT id FROM `content` ORDER BY id desc LIMIT ".($page-1)*$pagesize.", 1) AS t2 
WHERE t1.id <= t2.id ORDER BY t1.id desc LIMIT $pagesize;

经过我的测试，join分页和子查询分页的效率基本在一个等级上，消耗的时间也基本一致。

为什么会这样呢？因为子查询是在索引上完成的，而普通的查询时在数据文件上完成的，通常来说，索引文件要比数据文件小得多，所以操作起来也会更有效率。
实际可以利用类似策略模式的方式去处理分页，比如判断如果是一百页以内，就使用最基本的分页方式，大于一百页，则使用子查询的分页方式。
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
对于有大数据量的mysql表来说，使用LIMIT分页存在很严重的性能问题。

查询从第1000000之后的30条记录：
SQL代码1：平均用时6.6秒 SELECT * FROM `cdb_posts` ORDER BY pid LIMIT 1000000 , 30

SQL代码2：平均用时0.6秒 SELECT * FROM `cdb_posts` WHERE pid >= (SELECT pid FROM 
`cdb_posts` ORDER BY pid LIMIT 1000000 , 1) LIMIT 30

因为要取出所有字段内容，第一种需要跨越大量数据块并取出，而第二种基本通过直接根据索引字段定位后，才取出相应内容，效率自然大大提升。对limit的优化，不是直接使用limit，而是首先获取到offset的id，然后直接使用limit size来获取数据。

可以看出，越往后分页，LIMIT语句的偏移量就会越大，两者速度差距也会越明显。

实际应用中，可以利用类似策略模式的方式去处理分页，比如判断如果是一百页以内，就使用最基本的分页方式，大于一百页，则使用子查询的分页方式。
优化思想：避免数据量大时扫描过多的记录

为了保证index索引列连续，可以为每个表加一个自增字段，并且加上索引

优化思路:

利用子查询加分页,结合一个索引id加快查询效率

虽然查询次数变多但是单次查询效率变高,ok开始优化